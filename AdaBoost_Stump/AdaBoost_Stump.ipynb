{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost-Stump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def memo(f):\n",
    "    \"\"\"Memoization decorator, Used to accelerate the retrieval\"\"\"\n",
    "    cache = {}\n",
    "\n",
    "    def _f(*args):\n",
    "        try:\n",
    "            return cache[args]\n",
    "        except KeyError:\n",
    "            cache[args] = result = f(*args)\n",
    "            return result\n",
    "        # Some elements of args unhashable\n",
    "        except TypeError:\n",
    "            return f(args)\n",
    "\n",
    "    _f.cache = cache\n",
    "    return _f\n",
    "\n",
    "\n",
    "@memo\n",
    "def stump(args):\n",
    "    s, i, t, X = args\n",
    "    \"\"\"Decision stump for given direction s, dimension i, and threshold t\"\"\"\n",
    "    return np.apply_along_axis(lambda x: s * ((x[i] > t) * 2 - 1), 1, X)\n",
    "\n",
    "\n",
    "def accuracy(s, i, theta, w, X, y):\n",
    "    \"\"\"Calculate accuracy on training set for given decision stump\"\"\"\n",
    "    index = (stump(s, i, theta, X) == y)\n",
    "    return (np.dot(index * 1, w), index)\n",
    "\n",
    "\n",
    "def make_thresholds(L):\n",
    "    \"\"\"Given values of one dimension, let midpoints as thresholds\"\"\"\n",
    "    LS = [min(L) - 1] + sorted(L)\n",
    "    return [(LS[i] + LS[i + 1]) / 2 for i in range(len(LS) - 1)]\n",
    "\n",
    "\n",
    "def AdaBoost_Training(X, y, T):\n",
    "    \"\"\"T is the number iterations, train an AdaBoost binary classifer\"\"\"\n",
    "    # Initialize weight vector\n",
    "    weights = np.ones((X.shape[0],)) / X.shape[0]\n",
    "    alpha = []\n",
    "    g = []\n",
    "    Thr = []\n",
    "\n",
    "    # Compute threshold\n",
    "    for i in range(2):\n",
    "        Thr.append(make_thresholds(X[:, i]))\n",
    "\n",
    "    for r in range(T):\n",
    "        Max_Weighted_Accu = 0\n",
    "        index = []\n",
    "\n",
    "        for i in range(2):\n",
    "            for t in Thr[i]:\n",
    "                for s in [1, -1]:\n",
    "                    A, ind = accuracy(s, i, t, weights, X, y)\n",
    "\n",
    "                    if A > Max_Weighted_Accu:\n",
    "                        Max_Weighted_Accu, index = A, ind\n",
    "                        best = s, i, t\n",
    "\n",
    "        r_2 = Max_Weighted_Accu / (sum(weights) - Max_Weighted_Accu)\n",
    "        Rescale_Factor = np.sqrt(r_2)\n",
    "\n",
    "        # Rescaling the weight vector\n",
    "        weights[index] /= Rescale_Factor\n",
    "        weights[~index] *= Rescale_Factor\n",
    "\n",
    "        alpha.append(np.log(Rescale_Factor))\n",
    "        g.append(best)\n",
    "\n",
    "        if r % 10 == 9:\n",
    "            print('\\tNow is the %d-th iteration.' % (r + 1))\n",
    "\n",
    "    return g, alpha, weights\n",
    "\n",
    "\n",
    "def model_accuracy(g, alpha, T, X, y):\n",
    "    G = np.zeros((X.shape[0],))\n",
    "    for i in range(T):\n",
    "        params = list(g[i]) + [X]\n",
    "        G += np.array(stump(*params)) * alpha[i]\n",
    "\n",
    "    return sum(((G > 0) * 2 - 1) == y) / X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.757222</td>\n",
       "      <td>0.633831</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.847382</td>\n",
       "      <td>0.281581</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.249310</td>\n",
       "      <td>0.618635</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.538526</td>\n",
       "      <td>0.144259</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.474435</td>\n",
       "      <td>0.414558</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1  2\n",
       "0  0.757222  0.633831 -1\n",
       "1  0.847382  0.281581 -1\n",
       "2  0.249310  0.618635  1\n",
       "3  0.538526  0.144259 -1\n",
       "4  0.474435  0.414558 -1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training set:\n",
    "# https://d396qusza40orc.cloudfront.net/ntumltwo/hw2_data/hw2_adaboost_train.dat\n",
    "# Testing set:\n",
    "# https://d396qusza40orc.cloudfront.net/ntumltwo/hw2_data/hw2_adaboost_test.dat\n",
    "\n",
    "train_data = pd.read_csv('Data/hw2_adaboost_train.dat', sep=' ', header=None)\n",
    "test_data = pd.read_csv('Data/hw2_adaboost_test.dat', sep=' ', header=None)\n",
    "\n",
    "X = train_data[train_data.columns[:-1]].values\n",
    "y = train_data[train_data.columns[-1]].values\n",
    "\n",
    "X_test = test_data[test_data.columns[:-1]].values\n",
    "y_test = test_data[test_data.columns[-1]].values\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "\n",
      "\tNow is the 10-th iteration.\n",
      "\tNow is the 20-th iteration.\n",
      "\tNow is the 30-th iteration.\n",
      "\tNow is the 40-th iteration.\n",
      "\tNow is the 50-th iteration.\n",
      "\tNow is the 60-th iteration.\n",
      "\tNow is the 70-th iteration.\n",
      "\tNow is the 80-th iteration.\n",
      "\tNow is the 90-th iteration.\n",
      "\tNow is the 100-th iteration.\n",
      "\tNow is the 110-th iteration.\n",
      "\tNow is the 120-th iteration.\n",
      "\tNow is the 130-th iteration.\n",
      "\tNow is the 140-th iteration.\n",
      "\tNow is the 150-th iteration.\n",
      "\tNow is the 160-th iteration.\n",
      "\tNow is the 170-th iteration.\n",
      "\tNow is the 180-th iteration.\n",
      "\tNow is the 190-th iteration.\n",
      "\tNow is the 200-th iteration.\n",
      "\tNow is the 210-th iteration.\n",
      "\tNow is the 220-th iteration.\n",
      "\tNow is the 230-th iteration.\n",
      "\tNow is the 240-th iteration.\n",
      "\tNow is the 250-th iteration.\n",
      "\tNow is the 260-th iteration.\n",
      "\tNow is the 270-th iteration.\n",
      "\tNow is the 280-th iteration.\n",
      "\tNow is the 290-th iteration.\n",
      "\tNow is the 300-th iteration.\n",
      "\n",
      "\tAccuracy on Training set: 100.00 %\n",
      "\tAccuracy on Testing set: 86.80 %\n",
      "\tSmallest error of all stumps (train) 17.87 %\n",
      "\tAccuracy on Testing set of one stump: 71.00 %\n",
      "\n",
      "Done. Using 83.895319 seconds.\n"
     ]
    }
   ],
   "source": [
    "T = 300\n",
    "\n",
    "print('Start Training...\\n')\n",
    "start = time.clock()\n",
    "\n",
    "g, alpha, weights = AdaBoost_Training(X, y, T)\n",
    "\n",
    "train_accu = model_accuracy(g, alpha, T, X, y)\n",
    "print('\\n\\tAccuracy on Training set: %.2f %%' % (100 * train_accu))\n",
    "\n",
    "test_accu = model_accuracy(g, alpha, T, X_test, y_test)\n",
    "print('\\tAccuracy on Testing set: %.2f %%' % (100 * test_accu))\n",
    "\n",
    "min_err = min(list(map(lambda x: 1 / (np.exp(2 * x) + 1), alpha)))\n",
    "print('\\tSmallest error of all stumps (train) %.2f %%' % (100 * min_err))\n",
    "\n",
    "params = list(g[0]) + [X_test]\n",
    "one_accu = sum(stump(*params) == y_test) / 10.0\n",
    "print('\\tAccuracy on Testing set of one stump: %.2f %%' % (one_accu))\n",
    "\n",
    "print('\\nDone. Using %f seconds.' % (time.clock() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
