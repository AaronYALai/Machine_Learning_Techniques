{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class NeuralNet(object):\n",
    "    \"\"\"Deep Neural Network with square error metrics\"\"\"\n",
    "    def __init__(self, layers, activation='tanh', output = 'tanh', bias = True, initial = 0.1):\n",
    "        self.acti = self.Choose(activation); self.out = self.Choose(output)\n",
    "        self.layer = layers; self.L = len(layers)\n",
    "        self.bias = bias ; self.init = initial\n",
    "        self.weights = {}; self.gradient = {}\n",
    "        self.initialize_weights()\n",
    "    \n",
    "    def Choose(self,activation):\n",
    "        \"\"\"Choose the activation function\"\"\"\n",
    "        choose = dict({'tanh':self.tanh,'sigmoid':self.sigmoid,'ReLU':self.ReLU,'linear':self.linear})\n",
    "        return choose[activation]\n",
    "        \n",
    "    def initialize_weights(self):\n",
    "        \"\"\"Initialize the weights W and b\"\"\"\n",
    "        for i in range(self.L-1):\n",
    "            self.weights[i] = np.random.uniform(-self.init,self.init,(self.layer[i],self.layer[i+1]))\n",
    "            self.gradient[i] = np.zeros((self.layer[i],self.layer[i+1]))\n",
    "            if self.bias:  #bias parameters\n",
    "                self.weights[-1-i] = np.random.uniform(-self.init,self.init,self.layer[i+1])\n",
    "                self.gradient[-1-i] = np.zeros(self.layer[i+1])\n",
    "                \n",
    "    def get_param(self):\n",
    "        \"\"\"Print out all the parameters of the NNet\"\"\"\n",
    "        for i in range(self.L-1):\n",
    "            print(self.weights[i])\n",
    "            if self.bias:\n",
    "                print(self.weights[-1-i])\n",
    "                \n",
    "    def train(self, X, Y, batch=1, rate=0.1, epochs = 100):\n",
    "        \"\"\"Train NNet with backpropagation and mini-batch\"\"\"\n",
    "        for j in range(epochs):\n",
    "            Index = np.random.permutation(len(X))\n",
    "            b = 0\n",
    "            for ind in Index:\n",
    "                self.Forward(X[ind])\n",
    "                self.Backward(X[ind],Y[ind])\n",
    "                b += 1\n",
    "                if b == batch:\n",
    "                    self.Update(rate, batch)  \n",
    "                    b = 0\n",
    "                    \n",
    "    def Forward(self, x):\n",
    "        \"\"\"Forward propagation to get output for all layers\"\"\"\n",
    "        self.tmp_S = {}; self.tmp_A = {}\n",
    "        for i in range(self.L-1):\n",
    "            S = np.dot(x,self.weights[i]) if i==0 else np.dot(self.tmp_A[i-1],self.weights[i])\n",
    "            if self.bias:\n",
    "                S += self.weights[-1-i]\n",
    "            self.tmp_S[i] = S\n",
    "            self.tmp_A[i] = self.acti(S) if i < self.L-2 else self.out(S)\n",
    "        return self.tmp_A[self.L-2]  \n",
    "    \n",
    "    def Backward(self,x,y):\n",
    "        \"\"\"Calculate and accumulate the gradients with respect to each parameters\"\"\"\n",
    "        delta = -2*(y-self.tmp_A[self.L-2])*self.out(self.tmp_S[self.L-2],True)\n",
    "        self.gradient[self.L-2] += np.outer(self.tmp_A[self.L-3],delta)\n",
    "        if self.bias: #gradient with respect to bias weight parameters\n",
    "            self.gradient[1-self.L] += delta\n",
    "        for i in range(self.L-3):\n",
    "            delta = np.dot(self.weights[self.L-2-i],delta)*self.out(self.tmp_S[self.L-3-i],True)\n",
    "            if self.bias:\n",
    "                self.gradient[2-self.L+i] += delta\n",
    "            self.gradient[self.L-3-i] += np.outer(self.tmp_A[self.L-4-i],delta)\n",
    "        delta = np.dot(self.weights[1],delta)*self.out(self.tmp_S[0],True)\n",
    "        if self.bias:    \n",
    "            self.gradient[-1] += delta\n",
    "        self.gradient[0] += np.outer(x,delta)\n",
    "        \n",
    "    def Update(self,rate,batch):\n",
    "        \"\"\"Update weight parameters and reset gradients to 0\"\"\"\n",
    "        for i in range(self.L-1):\n",
    "            self.weights[i] -= rate*self.gradient[i]/batch\n",
    "            self.gradient[i] *= 0\n",
    "            if self.bias:\n",
    "                self.weights[-1-i] -= rate*self.gradient[-1-i]/batch\n",
    "                self.gradient[-1-i] *= 0\n",
    "                \n",
    "    def predict(self,X_t):\n",
    "        \"\"\"Use current parameters to predict\"\"\"\n",
    "        return np.array([self.Forward(x) for x in X_t])\n",
    "    \n",
    "    def tanh(self,X,grad=False):\n",
    "        \"\"\"tanh activation function and its gradient\"\"\"\n",
    "        return (1-np.tanh(X)**2) if grad else np.tanh(X)\n",
    "    \n",
    "    def sigmoid(self,X,grad=False):\n",
    "        \"\"\"sigmoid activation function and its gradient\"\"\"\n",
    "        E = np.exp(-X)\n",
    "        return E/(1+E)**2 if grad else 1/(1+E)\n",
    "    \n",
    "    def ReLU(self,X,grad=False):\n",
    "        \"\"\"ReLU activation function and its gradient\"\"\"\n",
    "        return np.where(X>0,1,0) if grad else np.where(X>0,X,0)\n",
    "    \n",
    "    def linear(self,X,grad=False):\n",
    "        \"\"\"linear activation function and its gradient\"\"\"\n",
    "        return X*0+1 if grad else X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Data = pd.read_csv('Data/hw4_nnet_train.dat',sep=' ',header=None)\n",
    "Xt = Data[[0,1]].values\n",
    "yt = Data[2].values\n",
    "\n",
    "Test = pd.read_csv('Data/hw4_nnet_test.dat',sep=' ',header=None)\n",
    "Xtest = Test[[0,1]].values\n",
    "ytest = Test[2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 689.50 seconds.\n",
      "Prediction error rate with respect to different structure:\n",
      " {16: 0.03848, 1: 0.2596, 11: 0.038400000000000004, 21: 0.037760000000000009, 6: 0.03848}\n"
     ]
    }
   ],
   "source": [
    "Record = dict()\n",
    "start = time.clock()\n",
    "for M in [1,6,11,16,21]:\n",
    "    R = []\n",
    "    for i in range(50):\n",
    "        NN =NeuralNet([2,M,1])\n",
    "        NN.train(Xt,yt,epochs=2000)\n",
    "        Prediction = NN.predict(Xtest)\n",
    "        R.append(np.sum((Prediction.T*ytest)<0)/len(Prediction))\n",
    "    Record[M] = np.mean(R)\n",
    "    \n",
    "print('Using %.2f seconds.'%(time.clock()-start))\n",
    "print(\"Prediction error rate with respect to different structure:\\n\",Record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 197.55 seconds. Eout = 0.036800\n"
     ]
    }
   ],
   "source": [
    "Record = dict()\n",
    "start = time.clock()\n",
    "R = []\n",
    "for i in range(50):\n",
    "    NN =NeuralNet([2,8,3,1])\n",
    "    NN.train(Xt,yt,epochs=2000,rate=0.01)\n",
    "    Prediction = NN.predict(Xtest)\n",
    "    R.append(np.sum((Prediction.T*ytest)<0)/len(Prediction))\n",
    "Eout = np.mean(R)\n",
    "    \n",
    "print('Using %.2f seconds. Eout = %.6f'%(time.clock()-start,Eout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
